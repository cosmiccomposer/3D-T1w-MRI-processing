{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'saveable_objects_from_trackable' from 'tensorflow.python.training.saving.saveable_object_util' (C:\\Users\\CSAS\\anaconda3\\envs\\gpu2\\lib\\site-packages\\tensorflow\\python\\training\\saving\\saveable_object_util.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu2\\lib\\site-packages\\tensorflow\\__init__.py:45\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[0;32m     43\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu2\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py:24\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m test\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tracking\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m types\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu2\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\tracking\\__init__.py:8\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf.__internal__.tracking namespace.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaveable_object_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m saveable_objects_from_trackable\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtracking\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautotrackable\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTrackable\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtracking\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CheckpointInitialValue\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'saveable_objects_from_trackable' from 'tensorflow.python.training.saving.saveable_object_util' (C:\\Users\\CSAS\\anaconda3\\envs\\gpu2\\lib\\site-packages\\tensorflow\\python\\training\\saving\\saveable_object_util.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.xception import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './clothing-dataset-small/train/t-shirt'\n",
    "name = '5f0a3fa0-6a3d-4b68-b213-72766a643de7.jpg'\n",
    "fullname = f'{path}/{name}'\n",
    "load_img(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img(fullname, target_size=(299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(img)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras.applications.xception import decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Xception(weights='imagenet', input_shape=(299, 299, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocess_input(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_predictions(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Higher values in feature map equate to higher simlilarity to the image when filtered.\n",
    "#integrate a multitude of feature maps for an increase in complexity   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/train', \n",
    "    target_size =(150, 150),\n",
    "    batch_size =32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/train', \n",
    "    target_size =(150, 150),\n",
    "    batch_size =32)\n",
    "val_gen = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "\n",
    "val_ds = val_gen.flow_from_directory( \n",
    "    './clothing-dataset-small/validation', \n",
    "    target_size =(150, 150),\n",
    "    batch_size =32,\n",
    "    shuffle = False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#establishing a model\n",
    "\n",
    "base_model = Xception(\n",
    "    weights= 'imagenet', \n",
    "    include_top= False,\n",
    "    input_shape= (150,150,3)\n",
    ")\n",
    "base_model.trainable =False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#establishing a model\n",
    "base_model = Xception(\n",
    "    weights= 'imagenet', \n",
    "    include_top= False,\n",
    "    input_shape= (150,150,3)\n",
    ")\n",
    "base_model.trainable =False\n",
    "#model recieves images, replacing the top layer filter\n",
    "inputs = keras.Input(shape=(150,150,3))\n",
    "\n",
    "base = base_model(inputs)\n",
    "\n",
    "vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
    "\n",
    "outputs = keras.layers.Dense(10)(vectors)\n",
    "\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from tensorflow import keras\n",
    "# # from tensorflow.keras import layers\n",
    "\n",
    "# # model = keras.Sequential()\n",
    "# # model.add(layers.Dense(64, kernel_initializer='uniform', input_shape=(10,)))\n",
    "# # model.add(layers.Activation('softmax'))\n",
    "\n",
    "# # opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "# # model.compile(loss='categorical_crossentropy', optimizer=opt)\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "# # Instantiate an optimizer.\n",
    "# optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# # Iterate over the batches of a dataset.\n",
    "# for x, y in dataset:\n",
    "#     # Open a GradientTape.\n",
    "#     with tf.GradientTape() as tape:\n",
    "#         # Forward pass.\n",
    "#         logits = model(x)\n",
    "#         # Loss value for this batch.\n",
    "#         loss_value = loss_fn(y, logits)\n",
    "\n",
    "#     # Get gradients of loss wrt the weights.\n",
    "#     gradients = tape.gradient(loss_value, model.trainable_weights)\n",
    "\n",
    "#     # Update the weights of the model.\n",
    "#     optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "# lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "#     initial_learning_rate=1e-2,\n",
    "#     decay_steps=10000,\n",
    "#     decay_rate=0.9)\n",
    "# optimizer = keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "learning_rate = 0.01\n",
    "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds, epochs=10, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history ['accuracy'], label='train')\n",
    "plt.plot(history.history ['val_accuracy'], label = 'val')\n",
    "plt.xticks(np.arange(10))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning rate model function;\n",
    "\n",
    "def make_model(learning_rate=0.01, size_inner=100):\n",
    "    base_model = Xception(\n",
    "    weights= 'imagenet', \n",
    "    include_top= False,\n",
    "    input_shape= (150,150,3)\n",
    "    )\n",
    "    base_model.trainable =False\n",
    "    \n",
    "########################################\n",
    "    inputs = keras.Input(shape=(150,150,3))\n",
    "    base = base_model(inputs)\n",
    "    vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
    "    inner = keras.layers.Dense(size_inner, activation='relu')(vectors)\n",
    "    outputs = keras.layers.Dense(10)(vectors)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "########################################\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    " \n",
    "    model.compile(\n",
    "        optimizer=optimizer, \n",
    "        loss=loss, \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "\n",
    "for lr in [0.0001, 0.001, 0.01, 0.1]:\n",
    "    print (lr)\n",
    "    \n",
    "    model = make_model(learning_rate=lr)\n",
    "    history = model.fit(train_ds, epochs=10, validation_data=val_ds)\n",
    "    scores[lr] = history.history\n",
    "    \n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del scores[0.1]\n",
    "del scores[0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr, hist in scores.items():\n",
    "#     plt.plot(hist['accuracy'], label='train=%s' % lr)\n",
    "    plt.plot(hist['val_accuracy'], label='val=%s' % lr)\n",
    "\n",
    "plt.xticks(np.arange(10))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model_v1.h5', save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#invoking callback checkpoints from model evaluation \n",
    "checkpoint=keras.callbacks.ModelCheckpoint(\n",
    "    'xception_v1_{epoch:02d}_{val_accuracy:.3f}.h5', \n",
    "    save_best_only=True,\n",
    "    monitor= 'val_accuracy',\n",
    "    mode='max'\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001 \n",
    "    \n",
    "model = make_model(learning_rate=learning_rate)\n",
    "history = model.fit(train_ds, \n",
    "        epochs=10, \n",
    "        validation_data=val_ds,\n",
    "        callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01 \n",
    "    \n",
    "model = make_model(learning_rate=learning_rate)\n",
    "history = model.fit(train_ds, \n",
    "        epochs=10, \n",
    "        validation_data=val_ds,\n",
    "        callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate= 0.001\n",
    "\n",
    "scores = {}\n",
    "\n",
    "for size in [10, 100, 1000]:\n",
    "    print(size)\n",
    "    \n",
    "    model = make_model(learning_rate=learning_rate, size_inner=size)\n",
    "    history = model.fit(train_ds, epochs=10, validation_data=val_ds)\n",
    "    scores[size] = history.history\n",
    "    \n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size, hist in scores.items():\n",
    "    plt.plot(hist['val_accuracy'], label=('val=%s' % size))\n",
    "\n",
    "plt.xticks(np.arange(10))\n",
    "# plt.yticks[(0.78, 0.80, 0.82, 0.825, 0.83)]\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning rate model function;\n",
    "\n",
    "def make_model(learning_rate=0.01, size_inner=100, droprate=0.5):\n",
    "    base_model = Xception(\n",
    "    weights= 'imagenet', \n",
    "    include_top= False,\n",
    "    input_shape= (150,150,3)\n",
    "    )\n",
    "    base_model.trainable =False\n",
    "    \n",
    "########################################\n",
    "    inputs = keras.Input(shape=(150,150,3))\n",
    "    base = base_model(inputs)\n",
    "    vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
    " #########################################\n",
    "    inner = keras.layers.Dense(size_inner, activation='relu')(vectors)\n",
    "    drop = keras.layers.Dropout(droprate)(inner)\n",
    " ##########################################    \n",
    "    outputs = keras.layers.Dense(10)(vectors)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "########################################\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    " \n",
    "    model.compile(\n",
    "        optimizer=optimizer, \n",
    "        loss=loss, \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate= 0.001\n",
    "size=100\n",
    "\n",
    "scores = {}\n",
    "\n",
    "for droprate in [0.0, 0.2, 0.5, 0.8]:\n",
    "    print(droprate)\n",
    "    \n",
    "    model = make_model(learning_rate=learning_rate, \n",
    "                       size_inner=size, \n",
    "                       droprate=droprate\n",
    "                      )\n",
    "    \n",
    "    history = model.fit(train_ds, epochs=30, validation_data=val_ds)\n",
    "    scores[droprate] = history.history\n",
    "    \n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for droprate, hist in scores.items():\n",
    "    plt.plot(hist['val_accuracy'], label=('val=%s' % droprate))\n",
    "\n",
    "plt.ylim(0.78, 0.86)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = scores[0.0]\n",
    "plt.plot(hist['val_accuracy'], label=0.0)\n",
    "\n",
    "hist = scores[0.2]\n",
    "plt.plot(hist['val_accuracy'], label=0.2)\n",
    "plt.legend()\n",
    "#plt.plot(hist['accuracy'], label=(['val=%s' % droprate]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tempfile\n",
    "# model_dir = tempfile.mkdtemp()\n",
    "# keras_estimator = tf.keras.estimator.model_to_estimator(\n",
    "#     keras_model=model, model_dir=model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transform(x, transform_parameters):\n",
    "    x= tf.keras.preprocesssing.image.apply_affine_transform(x,\n",
    "        transform_parameters.get('theta',0),\n",
    "        transform_parameters.get('tx',0),\n",
    "        transform_parameters.get('ty',0),\n",
    "        transform_parameters.get('shear',0),\n",
    "        transform_parameters.get('zx',0),\n",
    "        transform_parameters.get('zy',0),\n",
    "        row_axis=0,\n",
    "        col_axis=1,\n",
    "        channel_axis=2,\n",
    "        fill_mode='nearest',\n",
    "        cval=0.0,\n",
    "        order=1\n",
    ")\n",
    "    if transform_parameters.get('flip_horizontal', False):\n",
    "        x=x[::-1, :, :]\n",
    "    if transform_parameters.get('flip_vertical', False):\n",
    "        x=x[:, ::-1, :]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argument(img, \n",
    "            rotation=0,\n",
    "             height_shift=0,\n",
    "             width_shift=0,\n",
    "             shear=0, \n",
    "             zoom_x=1,\n",
    "             zoom_y=1,\n",
    "             flip_horizontal=0,\n",
    "             flip_vertical=0):\n",
    "             \n",
    "        x=np.array(img)\n",
    "             \n",
    "        transform_parameters ={\n",
    "        'theta': rotation,\n",
    "        'tx': height_shift,\n",
    "        'shear': shear,\n",
    "        'zx': zoom_x,\n",
    "        'zy': zoom_y,\n",
    "        'flip_horizontal': flip_horizontal,\n",
    "        'flip_vertical': flip_vertical,\n",
    "    }\n",
    "    \n",
    "        xaug = apply_transform(x, transform_parameters)\n",
    "        imgaug = Image.fromarray(xaug)\n",
    "        return imgaug\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_augmentations(params, values, figsize=(20,6)):\n",
    "    imgs = []\n",
    "    \n",
    "    for v in values:\n",
    "        im = argument(tshirt, **{param: v})\n",
    "        imgs.append(im)\n",
    "        \n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    n= len(values)\n",
    "    \n",
    "    for i in range(n):\n",
    "        plt.sublplot(1, n, i + i)\n",
    "        plt.imshow(np.array(imgs[i]))\n",
    "        plt.title('%s=%s'  % (param, values[1]))\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the image\n",
    "tshirt = Image.open('./clothing-dataset-small/train/t-shirt/5f0a3fa0-6a3d-4b68-b213-72766a643de7.jpg')\n",
    "tshirt = tshirt.resize((150, 150), resample=Image.NEAREST)\n",
    "tshirt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify varient augmentations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 3))\n",
    "\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(np.array(tshirt))\n",
    "plt.title('Original')\n",
    "plt.axis(\"off\")\n",
    "\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "\n",
    "img = argument(tshirt, flip_horizontal=1)\n",
    "plt.imshow(np.array(img))\n",
    "plt.title('Horizontal')\n",
    "plt.axis(\"off\")\n",
    "\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "\n",
    "img = argument(tshirt, flip_vertical=1)\n",
    "plt.imshow(np.array(img))\n",
    "plt.title('Vertical')\n",
    "plt.axis(\"off\")\n",
    "\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "\n",
    "img = argument(tshirt, flip_horizontal=1, flip_vertical=1)\n",
    "plt.imshow(np.array(img))\n",
    "plt.title('Both')\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 'rotation'\n",
    "values = [-30, -15, 0, 15, 30]\n",
    "show_augmentations(param, values, (10, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 'height_shift'\n",
    "values = [-30, -15, 0, 15, 30]\n",
    "show_augmentations(param, values, (10, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 'width_shift'\n",
    "values = [-30, -15, 0, 15, 30]\n",
    "show_augmentations(param, values, (10, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 'zoom_x'\n",
    "values = [0.25, 0.5, 1, 2, 4]\n",
    "show_augmentations(param, values, (10, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_gen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=5.0,\n",
    "    height_shift_range=5.0,\n",
    "    shear_range=10.0,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(tshirt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "for i in range(10):\n",
    "    t = vis_gen.get_random_transform((150, 150))\n",
    "    xaug = vis_gen.apply_transform(x, t)\n",
    "\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(xaug.astype('uint8'))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [0.5, 0.75, 1, 1.2, 1.5]\n",
    "\n",
    "imgs = []\n",
    "\n",
    "for v in values:\n",
    "    im = augment(tshirt, zoom_y=v, zoom_x=v)\n",
    "    imgs.append(im)\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "\n",
    "n = len(values)\n",
    "\n",
    "for i in range(n):\n",
    "    plt.subplot(1, n, i + 1)\n",
    "    plt.imshow(np.array(imgs[i]))\n",
    "    plt.title('%s=%s' % ('zoom', values[i]))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#299x299 model size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    shear_range=10, \n",
    "    zoon_range=0.1,\n",
    "    vertical_flip=False,\n",
    "    \n",
    "    \n",
    ")\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/train', \n",
    "    target_size =(150, 150),\n",
    "    batch_size =32)\n",
    "val_gen = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "\n",
    "val_ds = val_gen.flow_from_directory( \n",
    "    './clothing-dataset-small/validation', \n",
    "    target_size =(150, 150),\n",
    "    batch_size =32,\n",
    "    shuffle = False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate= 0.001\n",
    "size=100\n",
    "droprate = 0.2\n",
    "    \n",
    "    model = make_model(learning_rate=learning_rate, \n",
    "                       size_inner=size, \n",
    "                       droprate=droprate\n",
    "                      )\n",
    "    \n",
    "    history = model.fit(train_ds, epochs=50, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_size=150, learning_rate=0.01, size_inner=100, droprate=0.5):\n",
    "    base_model = Xception(\n",
    "    weights= 'imagenet', \n",
    "    include_top= False,\n",
    "    input_shape= (input_size, input_size, 3)\n",
    "    )\n",
    "    base_model.trainable =False\n",
    "    \n",
    "########################################\n",
    "    inputs = keras.Input(shape=(input_size, input_size, 3))\n",
    "    base = base_model(inputs)\n",
    "    vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
    " #########################################\n",
    "    inner = keras.layers.Dense(size_inner, activation='relu')(vectors)\n",
    "    drop = keras.layers.Dropout(droprate)(inner)\n",
    " ##########################################    \n",
    "    outputs = keras.layers.Dense(10)(vectors)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "########################################\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    " \n",
    "    model.compile(\n",
    "        optimizer=optimizer, \n",
    "        loss=loss, \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(prepr cessing_function=preprocess_input,\n",
    "                              shear_range=10,\n",
    "                              zoom_range=0.1,\n",
    "                                 horizontal_flip=True\n",
    "                              )\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/train', \n",
    "    target_size= (input_size, input_size),\n",
    "    batch_size =32\n",
    ")\n",
    "\n",
    "val_gen = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "\n",
    "val_ds = val_gen.flow_from_directory( \n",
    "    './clothing-dataset-small/validation', \n",
    "    target_size =(input_size, input_size),\n",
    "    batch_size =32,\n",
    "    shuffle = False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint=keras.callbacks.ModelCheckpoint(\n",
    "    'xception_v4_{epoch:02d}_{val_accuracy:.3f}.h5', \n",
    "    save_best_only=True,\n",
    "    monitor= 'val_accuracy',\n",
    "    mode='max'\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate= 0.0005\n",
    "size=100\n",
    "droprate = 0.2\n",
    "    \n",
    "\n",
    "    model = make_model(input_size=input_size,\n",
    "                       learning_rate=learning_rate, \n",
    "                       size_inner=size, \n",
    "                       droprate=droprate\n",
    "                      )\n",
    "    \n",
    "    history = model.fit(train_ds, epochs=50, validation_data=val_ds, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model('xception_v1_07_0.842.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.xception import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_gen = ImageDataGenerator(preprocessing_function=preprocess_input\n",
    "                             \n",
    "test_ds = test_gen.flow_from_directory(\n",
    "    './clothing-dataset-small-validation',\n",
    "    target_size=(299, 299),\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
